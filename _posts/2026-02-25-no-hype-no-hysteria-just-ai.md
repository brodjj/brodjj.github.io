---
title: "No Hype, No Hysteria, Just AI"
date: 2026-02-25 12:00:00 +1100
categories: [AI, Opinion]
tags: [ai, technology, critical thinking, start-here]
pin: true
---

Welcome to what I'm optimistically calling a "series" of articles about artificial intelligence. The goal here is simple: provide balanced, no-nonsense discussions about the state of AI from the 2020s onwards, without the techbro hype or apocalyptic pearl-clutching that seems to dominate every conversation about this technology.

I'm approaching this topic with a set of core philosophies to annoy both the AI evangelists and the doomsayers in equal measure:

## AI isn't inherently 'good' or 'bad'

It's a technology. Like any other technology, it can have positive or negative applications. It can be deployed well, and it can be deployed catastrophically badly (see: other entries in this series).

Fire gave us cooking and warmth. It also gave us arson. Electricity powers hospitals. It also powers pokie machines that cheat retirees out of their life savings. The internet connected the world. It also gave us social media. The technology itself is more or less neutral, it's what we do with it that matters.

AI is the same deal. It's not going to save humanity, and it's probably not going to exterminate us either. It's just another tool that humans will use to do both brilliant and spectacularly stupid things, often simultaneously.

## AI is here to stay

I hate to break it to you, but we're not rolling back the clock on this one. Thomas Hughes' theory of technological momentum suggests that once a technology reaches a certain level of adoption, it gathers inertia to proliferate more widely and become enmeshed in society. You can't un-invent it, and you can't wish it away.

We've seen this play out before. Personal computers went from niche hobby kits for nerds to being in every home and office. Mobile phones went from luxury item for stockbrokers to luxury item for entitled teenagers. The internet went from that "computer thing in university libraries" to being so fundamental to modern life that losing your Wi-Fi feels like a legitimate crisis.

AI is following the same trajectory. It's already baked into search engines, photo apps, customer service systems, and approximately seventeen million other things you interact with daily without realising. Companies have invested billions. Entire industries are reorganising around it. The infrastructure is being built. The momentum is there.

This doesn't mean we have to accept whatever gets thrown at us. But it does mean we need to engage with the reality of AI's presence rather than fantasising about a world where it doesn't exist. You can't opt out of living in a society shaped by AI any more than you can opt out of living in a society shaped by electricity or the combustion engine.

## The technology is complex and moving fast, but existing paradigms still apply

Here's where the conversation usually goes off the rails. Yes, AI is novel. Yes, it's fascinating. Yes, the technology is developing at a mind-blowing pace. But that doesn't mean we need to throw out every existing framework for thinking about technology, law, ethics, and accountability.

At the end of the day, AI is software. It's developed by companies to perform tasks, usually to make money. If it doesn't do its job accurately or safely, we shouldn't give it a pass just because it feels different to traditional software systems.

When your spreadsheet crashes and corrupts a month's worth of data, you don't shrug and say "well, software is just too complex to be held to normal standards." When your online banking app has a security flaw, the bank doesn't get to claim "the system is too mysterious for us to be responsible." When an autonomous vehicle kills someone, the company shouldn't escape liability because "AI is cutting edge."

A general theme you'll see throughout this series is discussing precedents, logic, and practices from the current tech and economic landscape that are readily applicable to AI. We've dealt with automation before. We've dealt with complex systems before. We've dealt with technologies that companies deploy without adequate testing before. We have legal frameworks, ethical principles, and regulatory approaches that work. Let's use them.

## Doomsday scenarios are (probably) unlikely

It's become sexy to talk about the real-life rise of Skynet. AI doom-mongering gets headlines, TED talks, and that coveted mix of fear and fascination that keeps people engaged. A malevolent superintelligence sounds possible in theory, but exactly how, or if, this could occur is up for debate.

Some commentators have even made timeline and probability projections for when AI will achieve consciousness, turn against us, or trigger some kind of technological singularity. These predictions sound authoritative until you realise they're essentially guesses built on assumptions stacked on top of other assumptions, with some linear algebra to make them seem more scientific.

Here's my take: We don't currently have the data, methodologies, or instruments to accurately predict if or when AI will develop into an existential threat. We can barely predict what the weather will do next week or which way the stock market will move, but apparently we're confident about mapping out the rise of machine consciousness? Yeah, nah.

However, where I differ from the AI evangelists and wild optimists is that I see the unknown as possibly containing danger, and that in itself is cause for proceeding with caution.

You don't just run into a dark cave and hope there isn't a bear inside. You look ahead. You bring a torch. You tread carefully. You maybe check if anyone else has been in the cave recently and whether they came back out. This isn't being a pessimist or a luddite, it's being sensible.

The real risks from AI aren't some far-future scenario where Skynet achieves consciousness and decides humans are the problem. The real risks are happening right now: Biased algorithms denying people housing, medical AI hallucinating dangerous advice, autonomous vehicles that don't stop for pedestrians, chatbots encouraging vulnerable people toward self-harm, and companies deploying half-baked systems without adequate testing because "moving fast and breaking things" is more profitable than "moving carefully and not breaking people".

Those risks are concrete, measurable, and causing actual harm today. Let's focus on those before we start worrying about whether ChatGPT 47 will decide to turn us all into batteries.

## Who am I, and why should you care?

Fair question. I'm an aging Xennial who's had a front-row seat to basically every major tech shift of the past few decades. My education, career, and life experience spans the analogue era, dumb phones, Internet 1.0, the dot-com boom and bust, Internet 2.0, smartphones, the rise of social media, the GFC, the enshittification of basically everything online, crypto, brain rot, and now the AI era.

I've worked in essential services (energy and water, the stuff that keeps society functioning when everything else goes to shit), higher education (where I learned that institutional bureaucracy is its own kind of AI in that it's mindless, inscrutable, and occasionally causes harm), IT, and digital project management (where I spent years watching people make the same mistakes with new technologies over and over again).

I'm writing these articles partly to develop my own knowledge and understanding, nothing forces you to actually think through your positions like having to explain them coherently to strangers on the internet. But I'm also writing them to encourage good-faith discussion about the utility and future of AI, because right now most of the public discourse oscillates between "AI will solve all of humanity's problems" and "AI will kill us all," with not a lot of nuance in between.

My goal with this series is to cut through the hype and the hysteria, look at what's actually happening with AI right now, apply some basic critical thinking and existing frameworks, and have honest conversations about what we should do about it. No clickbait doom predictions. No starry-eyed techno-utopianism. Just a realistic look at a technology that's already here and isn't going anywhere.
